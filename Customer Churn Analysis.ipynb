{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1290f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cabdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"Churn?\":\"Churn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ffe2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['State'], prefix=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"Phone\",axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04556af",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mapping = {'no': 0, 'yes': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Int'l Plan\"] = data[\"Int'l Plan\"].map(boolean_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"VMail Plan\"] = data[\"VMail Plan\"].map(boolean_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Churn\"] = label_encoder.fit_transform(data['Churn'])\n",
    "data[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Churn\",axis=1)\n",
    "y = data[\"Churn\"]\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"Logistic Regression\": {\"C\": [0.1, 1, 10, 100]},\n",
    "    \"K-Nearest Neighbors\": {\"n_neighbors\": [3, 5, 7, 9]},\n",
    "    \"Naive Bayes\": {},\n",
    "    \"Decision Tree\": {\"max_depth\": [None, 10, 20, 30]},\n",
    "    \"Random Forest\": {\"n_estimators\": [10, 50, 100, 200], \"max_depth\": [None, 10, 20, 30]},\n",
    "    \"Support Vector Machine\": {\"kernel\": [\"linear\",\"rbf\"], \"C\": [0.1, 1, 10, 100]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [10, 50, 100, 200], \"learning_rate\": [0.1, 0.01, 0.001]},\n",
    "    \"Neural Network\": {\n",
    "        \"hidden_layer_sizes\": [(1024, 512, 256, 128, 64, 32)], \"max_iter\": [500, 1000,5000,10000]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_classification(X_train,X_test,y_train,y_test,selected_model):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "\n",
    "        if selected_model in models:  # Check if selected_model is valid\n",
    "            model_instance = models[selected_model]\n",
    "            grid_search = GridSearchCV(model_instance, grid[selected_model], cv=5)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_params = grid_search.best_params_\n",
    "            model_instance.set_params(**best_params)\n",
    "            model_instance.fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Generate classification report\n",
    "            report = classification_report(y_test, y_pred,output_dict=True)\n",
    "\n",
    "             # Create a confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            parameters =  [selected_model, best_params, accuracy, report, cm]\n",
    "\n",
    "            return  parameters\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X,y,k =\"all\"):\n",
    "     # Select features and target column\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit and transform the scaler on training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Transform the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Initialize SelectKBest with the scoring function (f_classif for classification)\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "        # Fit the selector to your training data and transform the features\n",
    "        X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "        X_test_selected = selector.transform(X_test_scaled)\n",
    "        return X_train_selected, X_test_selected, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = feature_selection(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99710656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = {}\n",
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress FutureWarnings related to the mode function\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.neighbors\")\n",
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"K-Nearest Neighbors\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Naive Bayes\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Decision Tree\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd31c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0124ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Support Vector Machine\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Gradient Boosting\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = perform_classification(X_train,X_test,y_train,y_test,\"Neural Network\")\n",
    "\n",
    "if performance is not None:\n",
    "    model_performance.update({performance[0]: f'{performance[2]:.4f}', f\"{performance[0]} best_params\": performance[1]})\n",
    "    print(f\"**Model:** {performance[0]}\")\n",
    "    print(f\"**Best Hyperparameters:** {performance[1]}\")\n",
    "    print(f\"**Accuracy:** {performance[2]:.2f}\")\n",
    "    classification_report_df = pd.DataFrame(performance[3]).T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(classification_report_df.iloc[:, :3], annot=True, cmap=\"YlGnBu\", cbar=False, fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if performance[4] is not None:\n",
    "# Create a heatmap of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(performance[4], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title(f'{performance[0]} : Confusion Matrix', fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4331ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=(1024,512,256,128,64,32),max_iter= 1000)\n",
    "    \n",
    "    return joblib.dump(model, 'customer_churn_nn.joblib')\n",
    "    \n",
    "save_model()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
